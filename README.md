# ğŸ’¬ ChatSphere: Your Offline AI-Powered Conversational Assistant

ChatSphere is a privacy-first AI chatbot that runs **entirely on your local machine** using open-source large language models (LLMs) powered by [Ollama](https://ollama.com/). No cloud APIs, no internet required â€” just pure local inference with a sleek Streamlit interface.

---

## ğŸš€ Features

- ğŸ¤– Chat with open-source LLMs (e.g., LLaMA 2, Mistral)
- ğŸ§ Voice input using your microphone (optional)
- ğŸŒ™ Light/Dark theme toggle
- ğŸ§  Local inference via Ollama (no API key needed)
- ğŸ“œ Memory of previous chat history during the session
- ğŸ”„ Easy reset of chat
- âœ… Emoji replacements for expressive replies

---

## ğŸ§  Models You Can Use

You can use any Ollama-supported model, for example:

- `ollama run mistral`
- `ollama run llama2`
- `ollama run gemma`

âœ… Just make sure the model is running when you launch the app.

---

## ğŸ“¢ Voice Support

If you have a microphone and want to use voice input:

- Make sure the `speech_recognition` package is installed
- Use the ğŸ§ **Speak Query** button in the sidebar

> âš ï¸ Note: Microphone input may not work in cloud-hosted environments.

---

## ğŸ“Œ Notes

- ğŸ’¡ This chatbot does **not require an API key** if you're using Ollama.
- ğŸŒ This app is meant to run **locally only** and is **not deployed** to Streamlit Cloud.
- ğŸ”’ All conversations remain on your device â€” perfect for privacy-focused applications.

---

## ğŸ¤ Contributions

Contributions are welcome! Feel free to:

- Suggest improvements
- Add support for more models
- Improve UI or voice features

---

## ğŸ› ï¸ Installation Guide

### 1. Install Ollama

> ğŸ“Œ Ollama is a lightweight local LLM runner. Supports models like `llama2`, `mistral`, and more.

```bash
curl -fsSL https://ollama.com/install.sh | sh
```

## ğŸ› ï¸ Requirements

Install Python packages:
```bash
pip install -r requirements.txt
```
Run the app:
```bash
python -m streamlit run Ollama_LLM.py
```
> ğŸ—£ï¸ Visit the localhost in your browser to chat!
